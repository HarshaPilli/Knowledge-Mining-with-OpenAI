{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "# from utils import redis_helpers\n",
    "# from utils import helpers\n",
    "# from utils import language\n",
    "# from utils import openai_helpers\n",
    "# # from utils import storage\n",
    "# from utils import bot_helpers\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index km-openai Deleted\n",
      "Index km-openai created\n",
      "Deleted Skillset - km-openai-skills\n",
      "Created new Skillset - km-openai-skills\n",
      "Deleted Indexer - km-openai-indexer\n",
      "Deleted Data Source - km-openai-skills\n",
      "Created new Data Source Connection - km-openai-docs\n",
      "Created new Indexer - km-openai-indexer\n",
      "Running Indexer km-openai-indexer\n"
     ]
    }
   ],
   "source": [
    "#### Ingest all knowledge base documents\n",
    "from utils import cogsearch_helpers\n",
    "\n",
    "cogsearch_helpers.ingest_kb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reset Index in Redis\n",
    "from utils import redis_helpers\n",
    "\n",
    "reset_index = False\n",
    "\n",
    "if reset_index:\n",
    "    ADA_002_MODEL_MAX_TOKENS = os.environ[\"ADA_002_MODEL_MAX_TOKENS\"] \n",
    "\n",
    "    redis_conn = redis_helpers.get_new_conn()\n",
    "    redis_helpers.redis_reset_index(redis_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESET_REDIS = True\n",
    "\n",
    "if RESET_REDIS:\n",
    "    redis_helpers.redis_reset_index(ADA_002_EMBEDDING_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "CHOSEN_EMB_MODEL   = os.environ['CHOSEN_EMB_MODEL']\n",
    "SMALL_EMB_TOKEN_NUM  = int(os.environ['SMALL_EMB_TOKEN_NUM'])\n",
    "MEDIUM_EMB_TOKEN_NUM  = int(os.environ['MEDIUM_EMB_TOKEN_NUM'])\n",
    "LARGE_EMB_TOKEN_NUM  = int(os.environ['LARGE_EMB_TOKEN_NUM'])\n",
    "\n",
    "for item in os.listdir(\"dump\"):\n",
    "    path = os.path.join(\"dump\", item)\n",
    "\n",
    "    with open(path, 'r') as openfile:\n",
    "        data = json.load(openfile)\n",
    "        break\n",
    "\n",
    "emb_documents = []\n",
    "\n",
    "emb_documents += helpers.generate_embeddings(data, CHOSEN_EMB_MODEL, SMALL_EMB_TOKEN_NUM,  text_suffix = 'S')\n",
    "\n",
    "if MEDIUM_EMB_TOKEN_NUM != 0:\n",
    "    emb_documents += helpers.generate_embeddings(data, CHOSEN_EMB_MODEL, MEDIUM_EMB_TOKEN_NUM, text_suffix = 'M')\n",
    "\n",
    "if LARGE_EMB_TOKEN_NUM != 0:\n",
    "    emb_documents += helpers.generate_embeddings(data, CHOSEN_EMB_MODEL, LARGE_EMB_TOKEN_NUM,  text_suffix = 'L')\n",
    "\n",
    "helpers.load_embedding_docs_in_redis(emb_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_documents = []\n",
    "\n",
    "emb_documents += helpers.generate_embeddings_from_json_docs('dump', ADA_002_EMBEDDING_MODEL, ADA_002_MODEL_MAX_TOKENS, text_suffix='XL', limit=-1)\n",
    "# emb_documents += helpers.generate_embeddings_from_json_docs('dump', ADA_002_EMBEDDING_MODEL, 400, text_suffix='XS', limit=2)\n",
    "\n",
    "print(f\"Generated {len(emb_documents)} embeddings.\")\n",
    "helpers.save_embdding_docs_to_pkl(emb_documents, \"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 141 embeddings into Redis\n"
     ]
    }
   ],
   "source": [
    "emb_documents = helpers.load_embedding_docs_from_pkl(\"test.pkl\")\n",
    "helpers.load_embedding_docs_in_redis(emb_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "        \"in which classes did the Danish sailors qualify?\",\n",
    "        \"what are the reviews of the Lost City hotel?\"\n",
    "    ]\n",
    "\n",
    "\n",
    "for q in queries:\n",
    "    output = bot_helpers.openai_interrogate_text(q, DAVINCI_003_COMPLETIONS_MODEL, ADA_002_EMBEDDING_MODEL)\n",
    "    print(\"\\n\\n\", output, '\\n\\n\\n###############################')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrogating Text with embedding mode text-embedding-ada-002 and completion model text-davinci-003\n",
      "contacting oai\n",
      "##############################################################################\n",
      "Scores 0.167155265808 aHR0cHM6Ly9rbW9haXN0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L2ttb2FpZGVtby9BenVyZSUyME9wZW5BSSUyMFNlcnZpY2UlMjBMMTAwJTIwRGVjayUyMCgxKS5wcHR40_S_3\n",
      "Scores 0.184745430946 aHR0cHM6Ly9rbW9haXN0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L2ttb2FpZGVtby9taWNyb3NvZnQuanNvbg2_S_0\n",
      "Scores 0.200455665588 aHR0cHM6Ly9rbW9haXN0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L2ttb2FpZGVtby9BenVyZSUyME9wZW5BSSUyMFNlcnZpY2UlMjBMMTAwJTIwRGVjayUyMCgxKS5wcHR40_S_4\n",
      "Scores 0.201148748398 aHR0cHM6Ly9rbW9haXN0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L2ttb2FpZGVtby9BenVyZSUyME9wZW5BSSUyMFNlcnZpY2UlMjBMMTAwJTIwRGVjayUyMCgxKS5wcHR40_S_2\n",
      "Scores 0.202008366585 aHR0cHM6Ly9rbW9haXN0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L2ttb2FpZGVtby9BenVyZSUyME9wZW5BSSUyMFNlcnZpY2UlMjBMMTAwJTIwRGVjayUyMCgxKS5wcHR40_S_7\n",
      "original query length 21\n",
      "query length 21\n",
      "context length 10729\n",
      "empty prompt length 80\n",
      "max context tokens 3148\n",
      "full prompt length 3248\n",
      "Prompt \n",
      "    Context:  The ability to generate realistic, natural language explanations of current events could be a valuable resource for any news organization.\n",
      "5. Entertainment: GPT-3 could also be used to generate realistic, natural language descriptions of movies, TV shows, and other forms of entertainment. The ability to generate realistic, natural language explanations of entertainment concepts could be a valuable asset for any media company. \n",
      "1/19/2023 10:24 AM\n",
      "19\n",
      "Microsoft Office365\n",
      "© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.\n",
      "The information herein is for informational purposes only and represents the current view of Microsoft Corporation as of the date of this presentation. Because Microsoft must respond to changing market conditions, it should not be interpreted to be a commitment on the part of Microsoft, and Microsoft cannot guarantee the accuracy of any information provided after the date of this presentation. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION. Azure OpenAI Service                    Full Screen – Updated 12:20pm ET (Sept 16)  \n",
      "We’ve seen tremendous customer momentum, spanning industries and use cases. 20 Next steps\n",
      "To learn more, please visit Azure OpenAI Service’s product page. Have a use case? Speak to your Specialist / AE and sign up for access here: aka.ms/oai/access  \n",
      "1General guidance is to start with Davinci and then go down to see if a less sophisticated model can repeat the same results   \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED 21 Thank you   \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "22   \n",
      "Thank you © Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "23 \n",
      "GPT-3 models\n",
      "Inferencing time\n",
      "Capability Ada Curie Davinci Babbage Cushman-codex Davinci-codex\n",
      "Capability Codex models\n",
      "Azure OpenAI | Family of Models  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "24 Inferencing time\n",
      "Capability Ada\n",
      "Simple classification\n",
      "Parsing and formatting text Curie\n",
      "Answering questions\n",
      "Complex, nuanced classification  Davinci\n",
      "Summarizing for\n",
      "specific audience\n",
      "Generating creative content Babbage\n",
      "Semantic search ranking \n",
      "Moderately complex classification\n",
      "Azure OpenAI Service models Cushman-codex Davinci-codex\n",
      "Capability\n",
      "Codex\n",
      "GPT-3  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "Bob\n",
      "25 Generative pre-trained transformer 3 (GPT-3)\n",
      "Autoregressive language model that uses deep learning to produce human-like text\n",
      "Pre-trained on trillions of words\n",
      "Predicts the most likely next word based on input text\n",
      "General text-in/text-out interface \n",
      "Azure OpenAI | Overview of GPT-3  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "26             Powerful language models accessible to all skill levels\n",
      "Simple UX—validate proof of concepts fast\n",
      "Built in ML science intuition for everyone, with deeper controls for ML practitioners\n",
      "General purpose text-in/text-out\n",
      "interface—flexibility Azure OpenAI | GPT-3 Models  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "27   \n",
      "Prompt – Text input that provides some context to the engine on what is expecting.\n",
      "Completion – Output that GPT-3 generates based on the prompt. \n",
      "some context \n",
      "Azure OpenAI | GPT-3 Prompt Design  \n",
      "Prompt design (or prompt engineering)\n",
      "There are three basic guidelines to creating prompts:\n",
      "Show and tell. Make it clear what you want either through instructions, examples, or a combination of the two. If you want the model to rank a list of items in alphabetical order or to classify a paragraph by sentiment, show it that's what you want.\n",
      "Provide quality data. If you're trying to build a classifier or get the model to follow a pattern, make sure that there are enough examples. Be sure to proofread your examples — the model is usually smart enough to see through basic spelling mistakes and give you a response, but it also might assume this is intentional and it can affect the response.\n",
      "Check your settings. The temperature and top_p settings control how deterministic the model is in generating a response. If you're asking it for a response where there's only one right answer, then you'd want to set these lower. If you're looking for more diverse responses, then you might want to set them higher. The number one mistake people use with these settings is assuming that they're \"cleverness\" or \"creativity\" controls. \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "28 Model\n",
      "Davinci  Curie \n",
      "Babbage Ada\n",
      "Most capable GPT-3 model. Can do any task the other models can do, often with higher quality, longer output and better instruction-following.\n",
      "Very capable, but faster and lower cost than Davinci. Capable of straightforward tasks, very fast, and lower cost.\n",
      "Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\n",
      "Complex intent, cause and effect, summarization for audience Language translation, complex classification, text sentiment, summarization\n",
      "Moderate classification, semantic search classification\n",
      "Parsing text, simple classification, address correction, keywords\n",
      "4,000 tokens  2048 tokens \n",
      "2048 tokens 2048 tokens\n",
      "Request\n",
      "Description, performance, cost\n",
      "Use cases\n",
      "Azure OpenAI | GPT-3 Family of Models  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "While Davinci is generally the most capable, the other models can perform certain tasks extremely well with significant speed or cost advantages. For example, Curie can perform many of the same tasks as Davinci, but faster and for 1/10th the cost.\n",
      "We recommend using Davinci while experimenting since it will yield the best results. Once you’ve got things working, we encourage trying the other models to see if you can get the same results with lower latency. You may also be able to improve the other models’ performance by fine-tuning them on a specific task. 29 Iterate on ideas with \n",
      "a general-purpose \n",
      "text-in/text-out interface \n",
      "Prompt\n",
      "Summarize game commentary\n",
      "into highlights: Shey Peddy is applying ball pressure at the top against Sabrina Ionescu. At 7:48 remaining in the quarter; Peddy \n",
      "What are the main highlights of the game so far?\n",
      "Sample response \n",
      "The game has been close with Phoenix leading New York 7-5. Shey Peddy has been key for Phoenix.  Prompt\n",
      "Turn game commentary into highlights: Commentary: What a pickup she has\n",
      "Main highlights: New York has domina\n",
      "### Commentary:\n",
      "1. Turner is so important defensively to \n",
      "2. Griner pulled way out, Hartley with\n",
      "3. At 1:54 remaining in the quarter, Pho  Examples   Inputs\n",
      "Sample response \n",
      "Main highlights:\n",
      "1. New York has had a strong run in the  \n",
      "2. Phoenix leading by 1 point, 24-23\n",
      "3. New York Liberty's comeback has be  \n",
      "Results\n",
      "Prompt and completion examples Fine-tuning \"hyperparams\": { \n",
      "     \"batch_size\": 4, \n",
      "     \"learning_rate_multiplier\": 0.1, \n",
      "     \"n_epochs\": 4, \n",
      "     \"prompt_loss_weight\": 0.1, \n",
      "     \"use_packing\": true\n",
      "}\n",
      "Refine with examples \n",
      "(‘few shot learning’) with \n",
      "a simple UX\n",
      "Optimize accuracy and \n",
      "latency to validate proof \n",
      "of concept fast\n",
      "Azure OpenAI | GPT-3 Ideate, Experiment and Fine-Tune  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "30  Power BI Web Application Cosmos DB  PDF OCR pipeline\n",
      "Azure Cognitive Search Azure OpenAI Summarization Azure Forms Recognizer Documents\n",
      "Azure OpenAI | GPT-3 Sample High Level Architecture Document Processing and Summarisation  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "Azure Forms Recognizer “cracks” documents to read handwriting, text, tables, and process language to extract entities.\n",
      "Azure Cognitive Search then indexes the documents to make them \n",
      "Azure OpenAI Service provides a queryable interface to generate natural language summaries of the documents indexed by ACS\n",
      "CosmosDB stores\n",
      "\n",
      "\n",
      "{\n",
      "    \"id\": \"aHR0cHM6Ly9zY2NzdG9yYWdlb2dzZWFyY2guYmxvYi5jb3JlLndpbmRvd3MubmV0L3NlYXJjaC8yMDE4NjMucGRm0\",\n",
      "    \"categoryId\": \"KM_OAI_CATEGORY\",\n",
      "    \"timestamp\": [\n",
      "        \"1/1/1971 00:00:00 AM\"\n",
      "    ],\n",
      "    \"doc_url\": \"\",\n",
      "    \"text\": \"At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic, human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI Cognitive Services, I have been working with a team of amazing scientists and engineers to turn this quest into a reality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes of human cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At the intersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a joint representation to create more powerful AI that can speak, hear, see, and understand humans better. We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, spanning modalities and languages. The goal is to have pretrained models that can jointly learn representations to support a broad range of downstream AI tasks, much in the way humans do today. Over the past five years, we have achieved human performance on benchmarks in conversational speech recognition, machine translation, conversational question answering, machine reading comprehension, and image captioning. These five breakthroughs provided us with strong signals toward our more ambitious aspiration to produce a leap in AI capabilities, achieving multisensory and multilingual learning that is closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundational component of this aspiration, if grounded with external knowledge sources in the downstream AI tasks.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "marisation  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "Azure Forms Recognizer “cracks” documents to read handwriting, text, tables, and process language to extract entities.\n",
      "Azure Cognitive Search then indexes the documents to make them \n",
      "Azure OpenAI Service provides a queryable interface to generate natural language summaries of the documents indexed by ACS\n",
      "CosmosDB stores the documents, document text, and outputs of OpenAI in a dynamically scalable and globally reliable database.\n",
      "Results and output are then hosted on Web App (external) and Power BI (Internal)\n",
      "Function Apps is utilized to call various APIs in a serverless manner to improve responsiveness and reduce costs.\n",
      "31             \n",
      "Accelerates software development\n",
      "Makes APIs more accessible \n",
      "Widens who can code\n",
      "OpenAI Codex   \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "32 \n",
      "OpenAI Codex Models\n",
      "Derived from base models and trained on both NL and code (billions of Lines of Code)\n",
      "Support multiple programming languages\n",
      "Python, C#, SQL, Java, JavaScript, TypeScript, Go\n",
      "    \n",
      "    Question: Give an example of an Autoregressive language model that uses deep learning to produce human-like text.       \n",
      "    \n",
      "    Answer the question using the above Context only, and if the answer is not contained within the Context above, say \"Sorry, the query did not find a good match. Please rephrase your question\":\n",
      "    \n",
      "##############################################################################\n",
      "Link: https://kmoaistorage.blob.core.windows.net/kmoaidemo/Azure%20OpenAI%20Service%20L100%20Deck%20%281%29.pptx?se=2028-02-25T08%3A47%3A29Z&sp=r&sv=2021-12-02&sr=b&sig=J6gfKY8noQNU47hsRc15omtvMLjdoG1xn4z2d354CT8%3D\n",
      "\n",
      "\n",
      "Excerpt from Knowledge Base: \" The ability to generate realistic, natural language explanations of current events could be a valuable resource for any news organization.\n",
      "5. Entertainment: GPT-3 could also be used to generate realistic, natural language descriptions of movies, TV shows, and other forms of entertainment. The ability to generate realistic, natural language explanations of entertainment concepts could be a valuable asset for any media company. \n",
      "1/19/2023 10:24 AM\n",
      "19\n",
      "Microsoft Office365\n",
      "© 2012 Microsoft Corporation. All rights reserved. Microsoft, Windows, and other product names are or may be registered trademarks and/or trademarks in the U.S. and/or other countries.\n",
      "The information herein is for informational purposes only and represents the current view of Microsoft Corporation as of the date of this presentation. Because Microsoft must respond to changing market conditions, it should not be interpreted to be a commitment on the part of Microsoft, and Microsoft cannot guarantee the accuracy of any information provided after the date of this presentation. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION. Azure OpenAI Service                    Full Screen – Updated 12:20pm ET (Sept 16)  \n",
      "We’ve seen tremendous customer momentum, spanning industries and use cases. 20 Next steps\n",
      "To learn more, please visit Azure OpenAI Service’s product page. Have a use case? Speak to your Specialist / AE and sign up for access here: aka.ms/oai/access  \n",
      "1General guidance is to start with Davinci and then go down to see if a less sophisticated model can repeat the same results   \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED 21 Thank you   \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "22   \n",
      "Thank you © Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "23 \n",
      "GPT-3 models\n",
      "Inferencing time\n",
      "Capability Ada Curie Davinci Babbage Cushman-codex Davinci-codex\n",
      "Capability Codex models\n",
      "Azure OpenAI | Family of Models  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "24 Inferencing time\n",
      "Capability Ada\n",
      "Simple classification\n",
      "Parsing and formatting text Curie\n",
      "Answering questions\n",
      "Complex, nuanced classification  Davinci\n",
      "Summarizing for\n",
      "specific audience\n",
      "Generating creative content Babbage\n",
      "Semantic search ranking \n",
      "Moderately complex classification\n",
      "Azure OpenAI Service models Cushman-codex Davinci-codex\n",
      "Capability\n",
      "Codex\n",
      "GPT-3  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "Bob\n",
      "25 Generative pre-trained transformer 3 (GPT-3)\n",
      "Autoregressive language model that uses deep learning to produce human-like text\n",
      "Pre-trained on trillions of words\n",
      "Predicts the most likely next word based on input text\n",
      "General text-in/text-out interface \n",
      "Azure OpenAI | Overview of GPT-3  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "26             Powerful language models accessible to all skill levels\n",
      "Simple UX—validate proof of concepts fast\n",
      "Built in ML science intuition for everyone, with deeper controls for ML practitioners\n",
      "General purpose text-in/text-out\n",
      "interface—flexibility Azure OpenAI | GPT-3 Models  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "27   \n",
      "Prompt – Text input that provides some context to the engine on what is expecting.\n",
      "Completion – Output that GPT-3 generates based on the prompt. \n",
      "some context \n",
      "Azure OpenAI | GPT-3 Prompt Design  \n",
      "Prompt design (or prompt engineering)\n",
      "There are three basic guidelines to creating prompts:\n",
      "Show and tell. Make it clear what you want either through instructions, examples, or a combination of the two. If you want the model to rank a list of items in alphabetical order or to classify a paragraph by sentiment, show it that's what you want.\n",
      "Provide quality data. If you're trying to build a classifier or get the model to follow a pattern, make sure that there are enough examples. Be sure to proofread your examples — the model is usually smart enough to see through basic spelling mistakes and give you a response, but it also might assume this is intentional and it can affect the response.\n",
      "Check your settings. The temperature and top_p settings control how deterministic the model is in generating a response. If you're asking it for a response where there's only one right answer, then you'd want to set these lower. If you're looking for more diverse responses, then you might want to set them higher. The number one mistake people use with these settings is assuming that they're \"cleverness\" or \"creativity\" controls. \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "28 Model\n",
      "Davinci  Curie \n",
      "Babbage Ada\n",
      "Most capable GPT-3 model. Can do any task the other models can do, often with higher quality, longer output and better instruction-following.\n",
      "Very capable, but faster and lower cost than Davinci. Capable of straightforward tasks, very fast, and lower cost.\n",
      "Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\n",
      "Complex intent, cause and effect, summarization for audience Language translation, complex classification, text sentiment, summarization\n",
      "Moderate classification, semantic search classification\n",
      "Parsing text, simple classification, address correction, keywords\n",
      "4,000 tokens  2048 tokens \n",
      "2048 tokens 2048 tokens\n",
      "Request\n",
      "Description, performance, cost\n",
      "Use cases\n",
      "Azure OpenAI | GPT-3 Family of Models  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "While Davinci is generally the most capable, the other models can perform certain tasks extremely well with significant speed or cost advantages. For example, Curie can perform many of the same tasks as Davinci, but faster and for 1/10th the cost.\n",
      "We recommend using Davinci while experimenting since it will yield the best results. Once you’ve got things working, we encourage trying the other models to see if you can get the same results with lower latency. You may also be able to improve the other models’ performance by fine-tuning them on a specific task. 29 Iterate on ideas with \n",
      "a general-purpose \n",
      "text-in/text-out interface \n",
      "Prompt\n",
      "Summarize game commentary\n",
      "into highlights: Shey Peddy is applying ball pressure at the top against Sabrina Ionescu. At 7:48 remaining in the quarter; Peddy \n",
      "What are the main highlights of the game so far?\n",
      "Sample response \n",
      "The game has been close with Phoenix leading New York 7-5. Shey Peddy has been key for Phoenix.  Prompt\n",
      "Turn game commentary into highlights: Commentary: What a pickup she has\n",
      "Main highlights: New York has domina\n",
      "### Commentary:\n",
      "1. Turner is so important defensively to \n",
      "2. Griner pulled way out, Hartley with\n",
      "3. At 1:54 remaining in the quarter, Pho  Examples   Inputs\n",
      "Sample response \n",
      "Main highlights:\n",
      "1. New York has had a strong run in the  \n",
      "2. Phoenix leading by 1 point, 24-23\n",
      "3. New York Liberty's comeback has be  \n",
      "Results\n",
      "Prompt and completion examples Fine-tuning \"hyperparams\": { \n",
      "     \"batch_size\": 4, \n",
      "     \"learning_rate_multiplier\": 0.1, \n",
      "     \"n_epochs\": 4, \n",
      "     \"prompt_loss_weight\": 0.1, \n",
      "     \"use_packing\": true\n",
      "}\n",
      "Refine with examples \n",
      "(‘few shot learning’) with \n",
      "a simple UX\n",
      "Optimize accuracy and \n",
      "latency to validate proof \n",
      "of concept fast\n",
      "Azure OpenAI | GPT-3 Ideate, Experiment and Fine-Tune  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "30  Power BI Web Application Cosmos DB  PDF OCR pipeline\n",
      "Azure Cognitive Search Azure OpenAI Summarization Azure Forms Recognizer Documents\n",
      "Azure OpenAI | GPT-3 Sample High Level Architecture Document Processing and Summarisation  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "Azure Forms Recognizer “cracks” documents to read handwriting, text, tables, and process language to extract entities.\n",
      "Azure Cognitive Search then indexes the documents to make them \n",
      "Azure OpenAI Service provides a queryable interface to generate natural language summaries of the documents indexed by ACS\n",
      "CosmosDB stores\n",
      "\n",
      "\n",
      "{\n",
      "    \"id\": \"aHR0cHM6Ly9zY2NzdG9yYWdlb2dzZWFyY2guYmxvYi5jb3JlLndpbmRvd3MubmV0L3NlYXJjaC8yMDE4NjMucGRm0\",\n",
      "    \"categoryId\": \"KM_OAI_CATEGORY\",\n",
      "    \"timestamp\": [\n",
      "        \"1/1/1971 00:00:00 AM\"\n",
      "    ],\n",
      "    \"doc_url\": \"\",\n",
      "    \"text\": \"At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic, human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI Cognitive Services, I have been working with a team of amazing scientists and engineers to turn this quest into a reality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes of human cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At the intersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a joint representation to create more powerful AI that can speak, hear, see, and understand humans better. We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, spanning modalities and languages. The goal is to have pretrained models that can jointly learn representations to support a broad range of downstream AI tasks, much in the way humans do today. Over the past five years, we have achieved human performance on benchmarks in conversational speech recognition, machine translation, conversational question answering, machine reading comprehension, and image captioning. These five breakthroughs provided us with strong signals toward our more ambitious aspiration to produce a leap in AI capabilities, achieving multisensory and multilingual learning that is closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundational component of this aspiration, if grounded with external knowledge sources in the downstream AI tasks.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "marisation  \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED\n",
      "Azure Forms Recognizer “cracks” documents to read handwriting, text, tables, and process language to extract entities.\n",
      "Azure Cognitive Search then indexes the documents to make them \n",
      "Azure OpenAI Service provides a queryable interface to generate natural language summaries of the documents indexed by ACS\n",
      "CosmosDB stores the documents, document text, and outputs of OpenAI in a dynamically scalable and globally reliable database.\n",
      "Results and output are then hosted on Web App (external) and Power BI (Internal)\n",
      "Function Apps is utilized to call various APIs in a serverless manner to improve responsiveness and reduce costs.\n",
      "31             \n",
      "Accelerates software development\n",
      "Makes APIs more accessible \n",
      "Widens who can code\n",
      "OpenAI Codex   \n",
      "MICROSOFT CONFIDENTIAL – NON-DISCLOSURE AGREEMENT REQUIRED \n",
      "© Microsoft Corporation. All rights reserved. MICROSOFT MAKES NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, AS TO THE INFORMATION IN THIS PRESENTATION.\n",
      "1/19/2023 10:24 AM\n",
      "32 \n",
      "OpenAI Codex Models\n",
      "Derived from base models and trained on both NL and code (billions of Lines of Code)\n",
      "Support multiple programming languages\n",
      "Python, C#, SQL, Java, JavaScript, TypeScript, Go\"\n",
      "\n",
      "\n",
      "Answer: An example of an Autoregressive language model that uses deep learning to produce human-like text is Generative Pre-trained Transformer 3 (GPT-3). GPT-3 is a deep learning model that is pre-trained on trillions of words and is able to predict the most likely next word based on input text.\n"
     ]
    }
   ],
   "source": [
    "from utils import bot_helpers\n",
    "\n",
    "CHOSEN_EMB_MODEL   = os.environ['CHOSEN_EMB_MODEL']\n",
    "DAVINCI_003_COMPLETIONS_MODEL = os.environ['DAVINCI_003_COMPLETIONS_MODEL']\n",
    "#NUM_TOP_MATCHES = os.environ['NUM_TOP_MATCHES']\n",
    "\n",
    "query = \"in which classes did the Danish sailors qualify?\"\n",
    "query = \"Give an example of an Autoregressive language model that uses deep learning to produce human-like text.\"\n",
    "ans = bot_helpers.openai_interrogate_text(query, DAVINCI_003_COMPLETIONS_MODEL, CHOSEN_EMB_MODEL, 5, True)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cd1745cb8ae6036b9e0c2149eea914cda9394cff45b1c8e288267fc5648a26d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
